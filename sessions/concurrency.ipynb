{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Py4Eng](img/logo.png)\n",
    "\n",
    "# Concurrency\n",
    "## Yoav Ram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading\n",
    "\n",
    "Thread are very useful for maintaining multiple program flows running (quasi-)simultaneously: but in Python, they are really running in the same process so the main benefit from threading is that one job doesn't block other jobs from running simultaneously.\n",
    "\n",
    "Let's start with a simple example: a worker thread that counts from 1 to 10, waiting one second between numbers, but doesn't block the main thread that counts from 11 to 20 (also waiting). \n",
    "\n",
    "We use the [threading](https://docs.python.org/3.5/library/threading.html) module from the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_counting_task(start, end):\n",
    "    def task():\n",
    "        for i in range(start, end):\n",
    "            print(\" \", i, end=\" \")\n",
    "            time.sleep(1)\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   11    12  2   3   13   4   14   5   15   6   16   7   17   8   18   9   19   10   20 "
     ]
    }
   ],
   "source": [
    "main_task = create_counting_task(11, 21)\n",
    "worker_task = create_counting_task(1, 11)\n",
    "worker = threading.Thread(target=worker_task)\n",
    "worker.start()\n",
    "main_task()\n",
    "worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads in GUI applications\n",
    "\n",
    "GUI applications are a good example for when we want to have multiple program flows: the main thread might be responsible for the GUI, whereas worker threads might perform the logic. If the application is single-threaded, logic operations that take more than a few milliseconds might cause the GUI to \"hang\" which is big negative for user experience and prevents nice features like \"Cancel\", etc.\n",
    "\n",
    "For example, consider the Notepad application from the [GUI](gui.ipynb) session. Let's add a \"Word Count\" label that displays the number of words in the notepad. We easily write a method `update_word_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pyside-uic ../scripts/notepad.ui -o notepad_design.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%gui qt\n",
    "from PySide import QtGui\n",
    "from notepad_design import Ui_MainWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MainWindow(QtGui.QMainWindow, Ui_MainWindow):\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.setupUi(self)\n",
    "\n",
    "        ### methods connections removed for brevity, see sessions/gui.ipynb or scripts/notepad.py\n",
    "        self.update_word_count()\n",
    "        self.show()\n",
    "\n",
    "    ### methods removed for brevity, see sessions/gui.ipynb or scripts/notepad.py\n",
    "    \n",
    "    def update_word_count(self):\n",
    "        text = self.textEdit.toPlainText()\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "        self.counterLabel.setText('{:d}'.format(word_count))\n",
    "\n",
    "window = MainWindow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update the word count label by calling `update_word_count`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window.update_word_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we would like to do it automatically every second. For that we can use a thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MainWindow(QtGui.QMainWindow, Ui_MainWindow):\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.setupUi(self)\n",
    "\n",
    "        ### methods connections removed for brevity, see sessions/gui.ipynb or scripts/notepad.py\n",
    "            \n",
    "        # create word count update worker thread\n",
    "        def word_counter_update_task():\n",
    "            while self:\n",
    "                self.update_word_count()\n",
    "                time.sleep(1)\n",
    "                \n",
    "        self.word_count_updater = threading.Thread(target=word_counter_update_task, daemon=True)\n",
    "        self.word_count_updater.start()\n",
    "\n",
    "        self.show()      \n",
    "        \n",
    "    ### methods removed for brevity, see sessions/gui.ipynb or scripts/notepad.py\n",
    "    \n",
    "    def update_word_count(self):\n",
    "        text = self.textEdit.toPlainText()\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "        self.counterLabel.setText('{:d}'.format(word_count))\n",
    "\n",
    "window = MainWindow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a synchrounous program that reads books from the Gutenberg project and finds the most common word. Finding the most common word takes a while, but a lot less than reading the data from the web, so this is definately an I/O-bounded program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import urllib.request\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above']\n"
     ]
    }
   ],
   "source": [
    "stop_words_url = 'https://github.com/Alir3z4/stop-words/raw/25c6a0aea665871e887f155b883e950c3743ce50/english.txt'\n",
    "with urllib.request.urlopen(stop_words_url) as f:\n",
    "    stop_words = [line.decode().strip() for line in f]\n",
    "print(stop_words[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice in Wonderland.txt', <http.client.HTTPMessage at 0x508cba8>),\n",
       " ('The Importance of Being Earnest.txt',\n",
       "  <http.client.HTTPMessage at 0x528db38>),\n",
       " ('Metamorphosis .txt', <http.client.HTTPMessage at 0x528d588>),\n",
       " ('Pride and prejudice.txt', <http.client.HTTPMessage at 0x55c8d68>),\n",
       " ('A Tale of Two Cities.txt', <http.client.HTTPMessage at 0x52fcba8>),\n",
       " ('Frankenstein.txt', <http.client.HTTPMessage at 0x52fc9b0>),\n",
       " ('Gulliver.txt', <http.client.HTTPMessage at 0x52fce48>),\n",
       " ('Yellow wallpaper.txt', <http.client.HTTPMessage at 0x507ba20>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[urllib.request.urlretrieve(url, name+'.txt') for name, url in urls.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "    'Gulliver',\n",
    "    'Alice in Wonderland',\n",
    "    'Pride and prejudice',\n",
    "    'Yellow wallpaper',\n",
    "    'Metamorphosis ',\n",
    "    'A Tale of Two Cities',\n",
    "    'The Importance of Being Earnest',\n",
    "    'Frankenstein'\n",
    "]\n",
    "url_template = 'https://raw.githubusercontent.com/yoavram/Py4Eng/master/data/{}.txt'\n",
    "urls = {name: urllib.parse.quote(url_template.format(name), safe=\":/\") for name in names}\n",
    "\n",
    "def most_common_word(name, url):\n",
    "    with urllib.request.urlopen(url) as f:        \n",
    "        counter = Counter()\n",
    "        for line in f:        \n",
    "            if not line:\n",
    "                break\n",
    "            line = line.decode().lower()\n",
    "            counter.update(line.split())\n",
    "        for word in stop_words:\n",
    "            counter[word] = 0\n",
    "        word, count = counter.most_common(1)[0]\n",
    "        return name, word, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common word in Alice in Wonderland is \"said\" (130 appearances)\n",
      "Most common word in The Importance of Being Earnest is \"jack.\" (224 appearances)\n",
      "Most common word in Metamorphosis  is \"gregor\" (168 appearances)\n",
      "Most common word in Pride and prejudice is \"mr.\" (766 appearances)\n",
      "Most common word in A Tale of Two Cities is \"mr.\" (602 appearances)\n",
      "Most common word in Frankenstein is \"will\" (194 appearances)\n",
      "Most common word in Gulliver is \"upon\" (201 appearances)\n",
      "Most common word in Yellow wallpaper is \"project\" (81 appearances)\n",
      "Elapsed time: 21.90 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "for name, url in urls.items():\n",
    "    name, word, count = most_common_word(name, url)\n",
    "    print('Most common word in {} is \"{}\" ({} appearances)'.format(name, word, count))\n",
    "    \n",
    "toc = time.time()\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async program\n",
    "\n",
    "Since most of the time is spent waiting for I/O, we would like to wait for I/O in **parallel** rather than in **sequence**. To do that we can define **coroutines** - these are special task-like objects that are defined using `async def` (or in Python 3.4, using `def` with a special decorator). \n",
    "\n",
    "Coroutines can yield the control using the `await` statement (or `yield from` in Python < 3.5), which allows us to get something that is similar to multi-threading, but where the control switches occur in specific, designated, places in the code, and are entirely managed by us. This is in contrast to theads, in which control switches are managed by the operating system, which requires us (sometimes) to use locks and semaphors in order to make sure that our data stays \"whole\".\n",
    "\n",
    "Async programming with coroutines can enchance runtime in I/O-bouded programs, and the programmatic overhead is relatively small (as can be seen below). Moreover, coroutines are much cheaper than threads, in terms of their memory footprint, and therefore we can spawn thousands of them, while we cannot afford to spawn thousands of threads.\n",
    "\n",
    "Let's see an implementation of the above using async programming: we define the coroutine, which uses the *aiohttp* package to read files from the web instead of the *urllib* package: *aiohttp* does async HTTP requests and responses (both for servers and clients). We then instantiate the coroutines (much like we would do with generators, rather than functions). We create an event loop (using the standard library module *asyncio*), which will be responsible for running the coroutines and handling the switching of flow between them, give the loop all the coroutines, and run the loop. Lastly, We collect the async results and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "async def most_common_word(name, url):\n",
    "    response = await aiohttp.get(url)\n",
    "    assert response.status == 200\n",
    "    counter = Counter()\n",
    "    async for line in response.content:\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.decode().lower()\n",
    "        counter.update(line.split())\n",
    "    response.close()\n",
    "    for word in stop_words:\n",
    "        counter[word] = 0\n",
    "    word, count = counter.most_common(1)[0]\n",
    "    return name, word, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coroutine"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coros = [most_common_word(name, url) for name, url in urls.items()]\n",
    "loop = asyncio.get_event_loop()\n",
    "type(coros[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common word in The Importance of Being Earnest is \"jack.\" (224 appearances)\n",
      "Most common word in Metamorphosis  is \"gregor\" (168 appearances)\n",
      "Most common word in A Tale of Two Cities is \"mr.\" (602 appearances)\n",
      "Most common word in Alice in Wonderland is \"said\" (130 appearances)\n",
      "Most common word in Frankenstein is \"will\" (194 appearances)\n",
      "Most common word in Gulliver is \"upon\" (201 appearances)\n",
      "Most common word in Pride and prejudice is \"mr.\" (766 appearances)\n",
      "Most common word in Yellow wallpaper is \"project\" (81 appearances)\n",
      "Elapsed time: 3.05 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "tasks = loop.run_until_complete(asyncio.wait(coros))\n",
    "for t in tasks[0]:\n",
    "    name, word, count = t.result()\n",
    "    print('Most common word in {} is \"{}\" ({} appearances)'.format(name, word, count))\n",
    "    \n",
    "toc = time.time()\n",
    "print(\"Elapsed time: {:.2f} seconds\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing using IPython Parallel\n",
    "\n",
    "From the [threading](https://docs.python.org/3/library/threading.html) module:\n",
    "> CPython implementation detail: In CPython, due to the Global Interpreter Lock, **only one thread can execute Python code at once**... If you want your application to make better use of the **computational resources of multi-core machines**, you are advised to use `multiprocessing` or `concurrent.futures.ProcessPoolExecutor`.\n",
    "\n",
    "The standard library module, [multiprocessing](https://docs.python.org/3/library/multiprocessing.html), supports the use of multiple processes. \n",
    "\n",
    "However, we will use the [IPython Parallel](https://ipyparallel.readthedocs.org/) pacakge, which you can install with `conda install ipyparallel` or `pip install ipyparallel`. We'll start with some examples, but there are more [examples](http://nbviewer.jupyter.org/github/ipython/ipyparallel/blob/master/examples/Index.ipynb) and [demos](https://ipyparallel.readthedocs.org/en/latest/demos.html). *Note*: IPython Parallel is separate from the notebook and can run without it just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython Parallel lets us create a cluster. The default is to start a local cluster using subprocesses - let's start an IPython Cluster with 3 nodes:\n",
    "```\n",
    "ipcluster start -n 3\n",
    "```\n",
    "\n",
    "But in general we can also start a cluster using an MPI environment, SGE (qsub) environment, and other environments. You can also [start one cluster controller](https://ipyparallel.readthedocs.org/en/latest/process.html#starting-the-controller-and-engines-on-different-hosts) on one machine and then cluster engines on several other machines connected to the same LAN (or using SSH tunnels).\n",
    "\n",
    "Next, we create a cluster client, with a view that uses all cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = ipp.Client()\n",
    "v = rc.load_balanced_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first option for paralleling operations is by using the `map` method of the view instead of the regular `map` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple sync map:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "result = v.map(lambda x: 2*x, range(10))\n",
    "print(\"Simple sync map: \", list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use an async map which submits tasks, gives us back IDs, and we can then wait for the tasks to finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted tasks, got ids:  ['2fde147d-c1c4-425a-9d27-278d30feef88', '4af5560f-eef0-4e33-81af-2cbb94322502', 'dcfd248a-b0f3-4e29-b933-60e4d94574d1', 'b1818a89-8dba-4cd3-969f-d709e16e3f8f', '71a4f9bb-95dd-4e91-8d2c-52e219ad273e', 'd4d15f3f-63e7-434c-8f0a-4403780bc887', 'a6472ab8-3168-4d2e-8109-7e74bc9794bc', 'dca78456-2dbb-491f-8364-127a2ec23529', 'b3e4e3f5-cf67-4b41-9088-775388f9decb', '0df4e086-0c02-48f7-aeb6-5f993ed28934']\n",
      "Using a mapper:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "aresult = v.map_async(lambda x: 2*x, range(10))\n",
    "print(\"Submitted tasks, got ids: \", aresult.msg_ids)\n",
    "result = aresult.get()\n",
    "print(\"Using a mapper: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ipyparallel.client.asyncresult.AsyncMapResult, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aresult), type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a decorator to create a \"parallel function\" (with the sync or async approach, depending on if we specify `block=True` or `False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a parallel function:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "@v.parallel(block=True)\n",
    "def f(x): \n",
    "    return 2*x\n",
    "\n",
    "result = f.map(range(10))\n",
    "print(\"Using a parallel function: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `map` idiom doesn't quite fit our use case, we can just use `apply`. For example, take this function (details are in the [linear algebra session](linear-algebra.ipynb)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 1: 1.36 s per loop\n"
     ]
    }
   ],
   "source": [
    "def rand_mat_eigvals(bottom, top, n):\n",
    "    import numpy as np\n",
    "    X = np.random.randint(bottom, top, size=(n, n))\n",
    "    eigvals = np.linalg.eigvals(X)\n",
    "    return eigvals.max()\n",
    "%timeit -n 1 -r 1 rand_mat_eigvals(0, 9, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4001.0273477265564+0j),\n",
       " (3999.6972418514506+0j),\n",
       " (4000.2252682862822+0j),\n",
       " (4000.7451400583459+0j))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = v.apply_async(rand_mat_eigvals, 0, 9, 1000)\n",
    "res2 = v.apply_async(rand_mat_eigvals, 0, 9, 1000)\n",
    "res3 = v.apply_async(rand_mat_eigvals, 0, 9, 1000)\n",
    "res4 = v.apply_async(rand_mat_eigvals, 0, 9, 1000)\n",
    "res1.get(), res2.get(), res3.get(), res4.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we needed to import Numpy **inside** the function, otherwise the \"other\" processes wouldn't know what `np` is and will throw a `NameError`.\n",
    "\n",
    "Let's look at the example [wordfreq.py](https://github.com/ipython/ipyparallel/blob/master/examples/daVinci%20Word%20Count/wordfreq.py) and [pwordfreq.py](https://github.com/ipython/ipyparallel/blob/master/examples/daVinci%20Word%20Count/pwordfreq.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [General concepts in concurrency](https://learn-gevent-socketio.readthedocs.org/en/latest/general_concepts.html)\n",
    "- The [threading](https://docs.python.org/3/library/threading.html) module\n",
    "- The [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module\n",
    "- [IPython Parallel](https://ipyparallel.readthedocs.org/)\n",
    "- [distributed](https://distributed.readthedocs.org/en/latest/) by Continuum is a new package that facilitates data analysis on multiple machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colophon\n",
    "This notebook was written by [Yoav Ram](http://www.yoavram.com) and is part of the _Python for Engineers_ course.\n",
    "\n",
    "The notebook was written using [Python](http://pytho.org/) 3.4.4, [IPython](http://ipython.org/) 4.0.3 and [Jupyter](http://jupyter.org) 4.0.6.\n",
    "\n",
    "This work is licensed under a CC BY-NC-SA 4.0 International License.\n",
    "\n",
    "![Python logo](https://www.python.org/static/community_logos/python-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py4Eng",
   "language": "python",
   "name": "py4eng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
